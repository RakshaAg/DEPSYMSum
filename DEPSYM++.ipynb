{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DEPSYM++.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDSUhnCU3WXR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18a3045c-6f09-4a2a-b114-3a195cc6d83b"
      },
      "source": [
        "### pre requisites ###\n",
        "\n",
        "### install spacy\n",
        "!pip install spacy==2.2.4\n",
        "\n",
        "### install en model\n",
        "!python -m spacy download en_core_web_sm\n",
        "\n",
        "### install stanza\n",
        "!pip install spacy-stanza==0.2.4\n",
        "\n",
        "### install stanza model\n",
        "import stanza\n",
        "stanza.download(\"en\")\n",
        "\n",
        "### install truecase\n",
        "!pip install truecase\n",
        "\n",
        "### install textstat\n",
        "!pip install textstat"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spacy==2.2.4 in /usr/local/lib/python3.7/dist-packages (2.2.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4) (1.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4) (0.4.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4) (2.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4) (4.62.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4) (2.23.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4) (1.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4) (1.1.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4) (1.0.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4) (0.8.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4) (1.19.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4) (7.4.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4) (3.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4) (57.4.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy==2.2.4) (4.6.4)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy==2.2.4) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy==2.2.4) (3.5.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.4) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.4) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.4) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.4) (3.0.4)\n",
            "Collecting en_core_web_sm==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz (12.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.0 MB 14.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (57.4.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.62.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.6.4)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.5.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "Collecting spacy-stanza==0.2.4\n",
            "  Downloading spacy_stanza-0.2.4-py3-none-any.whl (9.1 kB)\n",
            "Requirement already satisfied: spacy<3.0.0,>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy-stanza==0.2.4) (2.2.4)\n",
            "Collecting stanza<1.2.0,>=1.0.0\n",
            "  Downloading stanza-1.1.1-py3-none-any.whl (227 kB)\n",
            "\u001b[K     |████████████████████████████████| 227 kB 5.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.1.0->spacy-stanza==0.2.4) (1.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.1.0->spacy-stanza==0.2.4) (2.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.1.0->spacy-stanza==0.2.4) (4.62.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.1.0->spacy-stanza==0.2.4) (1.1.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.1.0->spacy-stanza==0.2.4) (1.0.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.1.0->spacy-stanza==0.2.4) (7.4.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.1.0->spacy-stanza==0.2.4) (0.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.1.0->spacy-stanza==0.2.4) (57.4.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.1.0->spacy-stanza==0.2.4) (1.0.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.1.0->spacy-stanza==0.2.4) (1.19.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.1.0->spacy-stanza==0.2.4) (3.0.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.1.0->spacy-stanza==0.2.4) (2.23.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.1.0->spacy-stanza==0.2.4) (0.8.2)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<3.0.0,>=2.1.0->spacy-stanza==0.2.4) (4.6.4)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<3.0.0,>=2.1.0->spacy-stanza==0.2.4) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<3.0.0,>=2.1.0->spacy-stanza==0.2.4) (3.5.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0,>=2.1.0->spacy-stanza==0.2.4) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0,>=2.1.0->spacy-stanza==0.2.4) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0,>=2.1.0->spacy-stanza==0.2.4) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0,>=2.1.0->spacy-stanza==0.2.4) (2021.5.30)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from stanza<1.2.0,>=1.0.0->spacy-stanza==0.2.4) (3.17.3)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from stanza<1.2.0,>=1.0.0->spacy-stanza==0.2.4) (1.9.0+cu102)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf->stanza<1.2.0,>=1.0.0->spacy-stanza==0.2.4) (1.15.0)\n",
            "Installing collected packages: stanza, spacy-stanza\n",
            "Successfully installed spacy-stanza-0.2.4 stanza-1.1.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/master/resources_1.1.0.json: 122kB [00:00, 28.0MB/s]                    \n",
            "2021-08-24 17:14:37 INFO: Downloading default packages for language: en (English)...\n",
            "Downloading http://nlp.stanford.edu/software/stanza/1.1.0/en/default.zip: 100%|██████████| 428M/428M [01:18<00:00, 5.46MB/s]\n",
            "2021-08-24 17:16:04 INFO: Finished downloading models and saved to /root/stanza_resources.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting truecase\n",
            "  Downloading truecase-0.0.14-py3-none-any.whl (28.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 28.4 MB 57 kB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from truecase) (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->truecase) (1.15.0)\n",
            "Installing collected packages: truecase\n",
            "Successfully installed truecase-0.0.14\n",
            "Collecting textstat\n",
            "  Downloading textstat-0.7.2-py3-none-any.whl (101 kB)\n",
            "\u001b[K     |████████████████████████████████| 101 kB 3.2 MB/s \n",
            "\u001b[?25hCollecting pyphen\n",
            "  Downloading pyphen-0.11.0-py3-none-any.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 29.5 MB/s \n",
            "\u001b[?25hInstalling collected packages: pyphen, textstat\n",
            "Successfully installed pyphen-0.11.0 textstat-0.7.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOMIOA7xRRlf",
        "outputId": "6008d170-352c-4587-a27c-8930983db325"
      },
      "source": [
        " import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "from nltk.tokenize import sent_tokenize"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L68LbEFy5TQQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ded3b90d-5c35-4191-811a-7fc8e752c163"
      },
      "source": [
        "### install pattern\n",
        "\n",
        "!sudo apt-get install python-dev default-libmysqlclient-dev\n",
        "!sudo apt-get install python3-dev\n",
        "!pip install pattern"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "default-libmysqlclient-dev is already the newest version (1.0.4).\n",
            "default-libmysqlclient-dev set to manually installed.\n",
            "python-dev is already the newest version (2.7.15~rc1-1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 40 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "python3-dev is already the newest version (3.6.7-1~18.04).\n",
            "python3-dev set to manually installed.\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 40 not upgraded.\n",
            "Collecting pattern\n",
            "  Downloading Pattern-3.6.0.tar.gz (22.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 22.2 MB 65 kB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pattern) (0.16.0)\n",
            "Collecting backports.csv\n",
            "  Downloading backports.csv-1.0.7-py2.py3-none-any.whl (12 kB)\n",
            "Collecting mysqlclient\n",
            "  Downloading mysqlclient-2.0.3.tar.gz (88 kB)\n",
            "\u001b[K     |████████████████████████████████| 88 kB 8.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from pattern) (4.6.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from pattern) (4.2.6)\n",
            "Collecting feedparser\n",
            "  Downloading feedparser-6.0.8-py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 8.9 MB/s \n",
            "\u001b[?25hCollecting pdfminer.six\n",
            "  Downloading pdfminer.six-20201018-py3-none-any.whl (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 39.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pattern) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pattern) (1.4.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from pattern) (3.2.5)\n",
            "Collecting python-docx\n",
            "  Downloading python-docx-0.8.11.tar.gz (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 41.9 MB/s \n",
            "\u001b[?25hCollecting cherrypy\n",
            "  Downloading CherryPy-18.6.1-py2.py3-none-any.whl (419 kB)\n",
            "\u001b[K     |████████████████████████████████| 419 kB 44.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pattern) (2.23.0)\n",
            "Collecting cheroot>=8.2.1\n",
            "  Downloading cheroot-8.5.2-py2.py3-none-any.whl (97 kB)\n",
            "\u001b[K     |████████████████████████████████| 97 kB 6.0 MB/s \n",
            "\u001b[?25hCollecting jaraco.collections\n",
            "  Downloading jaraco.collections-3.4.0-py3-none-any.whl (10 kB)\n",
            "Collecting portend>=2.1.1\n",
            "  Downloading portend-2.7.1-py3-none-any.whl (5.3 kB)\n",
            "Collecting zc.lockfile\n",
            "  Downloading zc.lockfile-2.0-py2.py3-none-any.whl (9.7 kB)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.7/dist-packages (from cherrypy->pattern) (8.8.0)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from cheroot>=8.2.1->cherrypy->pattern) (1.15.0)\n",
            "Collecting jaraco.functools\n",
            "  Downloading jaraco.functools-3.3.0-py3-none-any.whl (6.8 kB)\n",
            "Collecting tempora>=1.8\n",
            "  Downloading tempora-4.1.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from tempora>=1.8->portend>=2.1.1->cherrypy->pattern) (2018.9)\n",
            "Collecting sgmllib3k\n",
            "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
            "Collecting jaraco.text\n",
            "  Downloading jaraco.text-3.5.1-py3-none-any.whl (8.1 kB)\n",
            "Collecting jaraco.classes\n",
            "  Downloading jaraco.classes-3.2.1-py3-none-any.whl (5.6 kB)\n",
            "Collecting cryptography\n",
            "  Downloading cryptography-3.4.7-cp36-abi3-manylinux2014_x86_64.whl (3.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2 MB 47.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet in /usr/local/lib/python3.7/dist-packages (from pdfminer.six->pattern) (3.0.4)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from pdfminer.six->pattern) (2.4.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography->pdfminer.six->pattern) (1.14.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography->pdfminer.six->pattern) (2.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pattern) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pattern) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pattern) (2.10)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from zc.lockfile->cherrypy->pattern) (57.4.0)\n",
            "Building wheels for collected packages: pattern, mysqlclient, python-docx, sgmllib3k\n",
            "  Building wheel for pattern (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pattern: filename=Pattern-3.6-py3-none-any.whl size=22332721 sha256=a3e8bc63b59407d0f15775ba8c2be7dfe6864584c2e3ece9dcdcb4acd7951a96\n",
            "  Stored in directory: /root/.cache/pip/wheels/8d/1f/4e/9b67afd2430d55dee90bd57618dd7d899f1323e5852c465682\n",
            "  Building wheel for mysqlclient (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mysqlclient: filename=mysqlclient-2.0.3-cp37-cp37m-linux_x86_64.whl size=100147 sha256=77a0a5b877028b76f334a7118d3bcd2236dbf96f5736300b834a258198ec2f76\n",
            "  Stored in directory: /root/.cache/pip/wheels/79/1c/f8/11fafab45fe6696eea63794a5d747b9c6b54990ac6f1885fb7\n",
            "  Building wheel for python-docx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-docx: filename=python_docx-0.8.11-py3-none-any.whl size=184508 sha256=0dae90c537548fdafc163994ffa50944cd45f7fff44cf3131695d2dc200ae90c\n",
            "  Stored in directory: /root/.cache/pip/wheels/f6/6f/b9/d798122a8b55b74ad30b5f52b01482169b445fbb84a11797a6\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6065 sha256=80044289ffa1332ba62284e10962988486171659ac7e533d53e81e53d7ea66ce\n",
            "  Stored in directory: /root/.cache/pip/wheels/73/ad/a4/0dff4a6ef231fc0dfa12ffbac2a36cebfdddfe059f50e019aa\n",
            "Successfully built pattern mysqlclient python-docx sgmllib3k\n",
            "Installing collected packages: jaraco.functools, tempora, jaraco.text, jaraco.classes, zc.lockfile, sgmllib3k, portend, jaraco.collections, cryptography, cheroot, python-docx, pdfminer.six, mysqlclient, feedparser, cherrypy, backports.csv, pattern\n",
            "Successfully installed backports.csv-1.0.7 cheroot-8.5.2 cherrypy-18.6.1 cryptography-3.4.7 feedparser-6.0.8 jaraco.classes-3.2.1 jaraco.collections-3.4.0 jaraco.functools-3.3.0 jaraco.text-3.5.1 mysqlclient-2.0.3 pattern-3.6 pdfminer.six-20201018 portend-2.7.1 python-docx-0.8.11 sgmllib3k-1.0.0 tempora-4.1.1 zc.lockfile-2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10RqFm7v3WXV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e088d286-a6cb-4dfb-bb76-a1ab2c48602a"
      },
      "source": [
        "import spacy\n",
        "from spacy import displacy\n",
        "import stanza\n",
        "from spacy_stanza import StanzaLanguage\n",
        "snlp = stanza.Pipeline(lang=\"en\")\n",
        "from pattern.en import comparative, superlative, conjugate, INFINITIVE, PRESENT, PAST, FUTURE, pluralize\n",
        "import truecase\n",
        "import re\n",
        "import textstat"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-08-24 17:16:45 INFO: Loading these models for language: en (English):\n",
            "=========================\n",
            "| Processor | Package   |\n",
            "-------------------------\n",
            "| tokenize  | ewt       |\n",
            "| pos       | ewt       |\n",
            "| lemma     | ewt       |\n",
            "| depparse  | ewt       |\n",
            "| sentiment | sstplus   |\n",
            "| ner       | ontonotes |\n",
            "=========================\n",
            "\n",
            "2021-08-24 17:16:45 INFO: Use device: cpu\n",
            "2021-08-24 17:16:45 INFO: Loading: tokenize\n",
            "2021-08-24 17:16:45 INFO: Loading: pos\n",
            "2021-08-24 17:16:46 INFO: Loading: lemma\n",
            "2021-08-24 17:16:46 INFO: Loading: depparse\n",
            "2021-08-24 17:16:48 INFO: Loading: sentiment\n",
            "2021-08-24 17:16:49 INFO: Loading: ner\n",
            "2021-08-24 17:16:50 INFO: Done loading processors!\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQWmkjtA3Doe"
      },
      "source": [
        "def inorder_traversal(token, removed=None):\n",
        "  if(token == None):\n",
        "     return \n",
        "  if(len(list(token.children)) == 0):\n",
        "     return token.text\n",
        "  s = \"\"\n",
        "  if(len(list(token.lefts)) != 0):\n",
        "    for child in token.lefts:\n",
        "      if(child != removed):\n",
        "        s = s + \" \" + inorder_traversal(child, removed)\n",
        "\n",
        "  s = s + \" \" + token.text\n",
        "\n",
        "  if(len(list(token.rights)) != 0):\n",
        "    for child in token.rights:\n",
        "      if(child != removed):\n",
        "        s = s + \" \" + inorder_traversal(child, removed)\n",
        "  return s\n",
        "\n",
        "def inorder_traversal_2(token, removed):\n",
        "  if(token == None):\n",
        "     return\n",
        "  if(len(list(token.children)) == 0):\n",
        "     return token.text\n",
        "  s = \"\"\n",
        "  if(len(list(token.lefts)) != 0):\n",
        "    for child in token.lefts:\n",
        "      if(child not in removed):\n",
        "        s = s + \" \" + inorder_traversal_2(child, removed)\n",
        "    \n",
        "  s = s + \" \" + token.text\n",
        "\n",
        "  if(len(list(token.rights)) != 0):\n",
        "    for child in token.rights:\n",
        "      if(child not in removed):\n",
        "        s = s + \" \" + inorder_traversal_2(child, removed)\n",
        "  return s\n",
        "\n",
        "def inorder_traversal_3(token, removed):\n",
        "  if(token == None):\n",
        "     return\n",
        "  if(len(list(token.children)) == 0):\n",
        "     return token.text\n",
        "  s = \"\"\n",
        "  if(len(list(token.lefts)) != 0):\n",
        "    for child in token.lefts:\n",
        "      if(child not in removed):\n",
        "        s = s + \" \" + inorder_traversal_3(child, removed)\n",
        "  if(token not in removed):\n",
        "    s = s + \" \" + token.text\n",
        "\n",
        "  if(len(list(token.rights)) != 0):\n",
        "    for child in token.rights:\n",
        "      if(child not in removed):\n",
        "        s = s + \" \" + inorder_traversal_3(child, removed)\n",
        "  return s\n",
        "\n",
        "def left_subtree(token):\n",
        "  if(token == None):\n",
        "     return\n",
        "  if(len(list(token.lefts)) == 0):\n",
        "     return token.text\n",
        "  s = \"\"\n",
        "  if(len(list(token.lefts)) != 0):\n",
        "    for child in token.lefts:\n",
        "      s = s + \" \" + inorder_traversal(child)\n",
        "  s = s + \" \" + token.text\n",
        "  return s\n",
        "\n",
        "def left_subtree_2(token, removed=None):\n",
        "  if(token == None):\n",
        "     return\n",
        "  if(len(list(token.children)) == 0):\n",
        "     return token.text\n",
        "  s = \"\"\n",
        "  if(len(list(token.lefts)) != 0):\n",
        "    for child in token.lefts:\n",
        "      if(child != removed):\n",
        "        s = s + \" \" + inorder_traversal(child, removed)\n",
        "\n",
        "  s = s + \" \" + token.text\n",
        "  return s\n",
        "\n",
        "def left_subtree_3(token, removed):\n",
        "  if(token == None):\n",
        "     return\n",
        "  if(len(list(token.children)) == 0):\n",
        "     return token.text\n",
        "  s = \"\"\n",
        "  if(len(list(token.lefts)) != 0):\n",
        "    for child in token.lefts:\n",
        "      if(child not in removed):\n",
        "        s = s + \" \" + inorder_traversal_3(child, removed)\n",
        "\n",
        "  if(token not in removed):\n",
        "    s = s + \" \" + token.text\n",
        "  return s\n",
        "\n",
        "\n",
        "def right_subtree_3(token, removed):\n",
        "  if(token == None):\n",
        "     return\n",
        "  if(len(list(token.children)) == 0):\n",
        "     return token.text\n",
        "  s = \"\"\n",
        "  if(len(list(token.rights)) != 0):\n",
        "    for child in token.rights:\n",
        "      if(child not in removed):\n",
        "        s = s + \" \" + inorder_traversal_3(child, removed)\n",
        "\n",
        "  if(token not in removed):\n",
        "    s = s + \" \" + token.text\n",
        "  return s\n",
        "\n",
        "def get_root(doc):\n",
        "  root  = None\n",
        "  for token in doc:\n",
        "    if(token.dep_ == \"ROOT\"):\n",
        "      root = token\n",
        "      return root\n",
        "\n",
        "def get_root_stanza(doc):\n",
        "  root  = None\n",
        "  for token in doc:\n",
        "    if(token.dep_ == \"root\"):\n",
        "      root = token\n",
        "      return root\n",
        "\n",
        "def get_tag(token, tag):\n",
        "  for child in token.children:\n",
        "    if(child.dep_ == tag):\n",
        "      return child\n",
        "\n",
        "def find_in_subtree(token, tag):\n",
        "  if(token == None):\n",
        "     return\n",
        "  if(token.tag_ == tag):\n",
        "     return token\n",
        "  for child in token.subtree:\n",
        "    if(child.dep_ == tag):\n",
        "      return child\n",
        "\n",
        "def find_in_children(token, tag):\n",
        "  if(token == None):\n",
        "     return\n",
        "  if(token.tag_ == tag):\n",
        "     return token\n",
        "  for child in token.children:\n",
        "    if(child.dep_ == tag):\n",
        "      return child\n",
        "\n",
        "def pos_in_subtree(token, tag):\n",
        "  if(token == None):\n",
        "     return False\n",
        "  if(token.pos_ == tag):\n",
        "     return True\n",
        "  for child in token.subtree:\n",
        "    if(child.pos_ == tag):\n",
        "      return True\n",
        "  return False\n",
        "\n",
        "def auxiliary_verb(verb, subj):\n",
        "  aux='are '\n",
        "  if subj.tag_ in (\"NN\", \"NNP\"):\n",
        "    if verb.tag_ in (\"VBP\", \"VBZ\", \"VB\"):\n",
        "      aux = \"is \"\n",
        "    elif verb.tag_ in (\"VBD\", \"VBG\", \"VBN\"):\n",
        "      aux = \"was \"\n",
        "    else: \n",
        "      aux = \"are \"\n",
        "  elif subj.tag_ in (\"NNS\", \"NNPS\"):\n",
        "    if verb.tag_ in (\"VBP\", \"VBZ\", \"VB\"):\n",
        "      aux = \"are \"\n",
        "    elif verb.tag_ in (\"VBD\", \"VBG\", \"VBN\"):\n",
        "      aux = \"were \"\n",
        "    else:\n",
        "      aux = \"are \"\n",
        "  elif subj.tag_ in (\"PRP\") and subj.text.lower() == \"they\":\n",
        "    if verb.tag_ in (\"VBP\", \"VBZ\", \"VB\") :\n",
        "      aux = \"are \"\n",
        "    elif verb.tag_ in (\"VBD\", \"VBG\", \"VBN\"):\n",
        "      aux = \"were \"\n",
        "  elif subj.tag_ in (\"PRP\"):\n",
        "    if verb.tag_ in (\"VBP\", \"VBZ\", \"VB\"):\n",
        "      aux = \"is \"\n",
        "    elif verb.tag_ in (\"VBD\", \"VBG\", \"VBN\"):\n",
        "      aux = \"was \"\n",
        "  else:\n",
        "      aux = \"are \"\n",
        "  return aux\n",
        "\n",
        "def remove_punct(s):\n",
        "    s_list = list(s.split(\" \"))\n",
        "    if(s_list[0] in ['?', '!', ',', ';', '.']):\n",
        "        s_list[0] = \"\"\n",
        "    for i in range(len(s_list)):\n",
        "        if(len(s_list[i]) > 0 and (s_list[i][0] == \".\" or s_list[i][0] == \",\")):\n",
        "            s_list[i] = \".\"\n",
        "    s = \" \".join(c for c in s_list)\n",
        "    fix_spaces = re.compile(r'\\s*([?!.,]+(?:\\s+[?!.,]+)*)\\s*')\n",
        "    s = fix_spaces.sub(lambda x: \"{} \".format(x.group(1).replace(\" \", \"\")), s)\n",
        "    s = truecase.get_true_case(s)\n",
        "    return s\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OlqDeBTS3Dof",
        "outputId": "f8bb9f53-83ce-43e7-8ec9-91c199905741"
      },
      "source": [
        "def appositive_simplification_2(comp_sent):\n",
        "  nlp = spacy.load(\"en_core_web_sm\")\n",
        "  doc = nlp(comp_sent)\n",
        "\n",
        "  root = get_root(doc)\n",
        "  subj = get_tag(root, \"nsubj\")\n",
        "\n",
        "  apposcl = None\n",
        "\n",
        "  apposcl = find_in_subtree(root, \"appos\")\n",
        "\n",
        "  if(apposcl == None):\n",
        "    apposcl = find_in_subtree(root, \"amod\")\n",
        "    if(apposcl != None):\n",
        "      if(apposcl.head.dep_ != \"nsubj\"):\n",
        "        #print(\"Appos: No simplification(no subject)\")\n",
        "        return False, comp_sent\n",
        "    else:\n",
        "      #print(\"Appos: No simplification\")\n",
        "      return False, comp_sent\n",
        "\n",
        "  appos_subj = apposcl.head\n",
        "  \n",
        "  appos_phrase = inorder_traversal(apposcl)\n",
        "  aux_verb = str(auxiliary_verb(root, appos_subj))\n",
        "  noun_phrase = left_subtree_2(appos_subj, apposcl)\n",
        "  sentence1 = inorder_traversal(root, apposcl)\n",
        "  sentence1 = ' '.join(sentence1.split(\",\")) \n",
        "  sentence1 = ' '.join(sentence1.split()) + \".\"\n",
        "\n",
        "  sentence2 = noun_phrase + \" \" + aux_verb + appos_phrase\n",
        "  sentence2 = ' '.join(sentence2.split(\",\")) \n",
        "  sentence2 = ' '.join(sentence2.split()) + \".\"\n",
        "\n",
        "  sentence1 = remove_punct(sentence1)\n",
        "  sentence2 = remove_punct(sentence2)\n",
        "\n",
        "  #print(sentence1)\n",
        "  #print(sentence2)\n",
        "  return True, sentence1 + \" \" + sentence2\n",
        "\n",
        "appositive_simplification_2(\"Siddharth, 21 years old, will join the company as an executive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(True,\n",
              " 'Siddharth will join the company as an executive. Siddharth is 21 years old.')"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jukLX7473Dog",
        "outputId": "c8f52637-5a42-4d88-bf12-754d1805243d"
      },
      "source": [
        "def rel_order(token):\n",
        "  if(token.dep_ == \"nsubj\" or token.dep_ == \"nsubjpass\"):\n",
        "    return True\n",
        "  else:\n",
        "    return False\n",
        "\n",
        "def relative_clause_simplify(cmp_snt):\n",
        "  nlp = spacy.load(\"en_core_web_sm\") \n",
        "  doc = nlp(cmp_snt)\n",
        "  root = get_root(doc)\n",
        "  relcl = None\n",
        "  relcl = find_in_subtree(root, \"relcl\")\n",
        "  if(relcl == None):\n",
        "    relcl = find_in_subtree(root, \"rcmod\")\n",
        "\n",
        "  if(relcl == None):\n",
        "    #print(\"Relcl: No simplification\")\n",
        "    return False, cmp_snt\n",
        "\n",
        "  subj = relcl.head\n",
        "  #print(relcl.left_edge.i)\n",
        "  #print(relcl.i)\n",
        "  #print(relcl)\n",
        "\n",
        "\n",
        "  rel_phrase = doc[relcl.left_edge.i : relcl.right_edge.i+1].text\n",
        "  \n",
        "\n",
        "  noun_phrase = left_subtree_2(subj, relcl)\n",
        "  sentence1 = inorder_traversal(root, relcl)\n",
        "  sentence1 = ' '.join(sentence1.split(\",\")) \n",
        "  sentence1 = ' '.join(sentence1.split()) + \".\"\n",
        "\n",
        " \n",
        "  sentence2 = noun_phrase + \" \" + rel_phrase\n",
        "  sentence2 = ' '.join(sentence2.split(\",\")) \n",
        "  sentence2 = ' '.join(sentence2.split()) \n",
        "  sentence2 = ' '.join(sentence2.split()) + \".\"\n",
        "  sentence2=  noun_phrase+ \" \"+ ' '.join(rel_phrase.split(' ')[1:])\n",
        "  sentence2 = ' '.join(sentence2.split(\",\")) +\".\"\n",
        "  if relcl.i!=relcl.left_edge.i+1:\n",
        "    #print(doc[relcl.left_edge.i].head)\n",
        "    sentence2 = doc[relcl.left_edge.i+1 :doc[relcl.left_edge.i].head.i+1].text+' '+noun_phrase+' '+doc[doc[relcl.left_edge.i].head.i+1 : relcl.right_edge.i+1].text\n",
        "    sentence2 = ' '.join(sentence2.split(\",\")) + \".\"\n",
        "  if doc[relcl.left_edge.i].dep_ in ['nsubj', 'nsubjpass']:\n",
        "    #print(doc[relcl.left_edge.i].head)\n",
        "    sentence2 = noun_phrase+ \" \"+ ' '.join(rel_phrase.split(' ')[1:])\n",
        "    sentence2 = ' '.join(sentence2.split(\",\")) + \".\"\n",
        "  \n",
        "  if rel_phrase.split(' ')[0].lower()=='where':\n",
        "    h=subj.head.text\n",
        "    sentence2=  ' '.join(rel_phrase.split(' ')[1:]) +\" \"+ h+\" \" +noun_phrase\n",
        "    sentence2 = ' '.join(sentence2.split(\",\")) + \".\"\n",
        "    if h not in ['at','in']:\n",
        "      sentence2=  ' '.join(rel_phrase.split(' ')[1:]) +\" \"+'at'+\" \" +noun_phrase\n",
        "      sentence2 = ' '.join(sentence2.split(\",\")) + \".\"\n",
        "    \n",
        "  #print(rel_phrase)\n",
        "  if rel_phrase.split(' ')[0].lower()=='whose':\n",
        "    #h=subj.head.text\n",
        "    sentence2 = noun_phrase + \" \" + rel_phrase\n",
        "    if noun_phrase[-1]!='s':\n",
        "      sentence2=  noun_phrase+\"'s\"+ \" \"+ ' '.join(rel_phrase.split(' ')[1:])\n",
        "    if noun_phrase[-1]=='s':\n",
        "      sentence2=  noun_phrase+\"'\"+ \" \"+ ' '.join(rel_phrase.split(' ')[1:])\n",
        "    sentence2 = ' '.join(sentence2.split(\",\")) +\".\"\n",
        "  \n",
        " \n",
        "  sent1_doc = nlp(sentence1)\n",
        "  sent1_root = get_root(sent1_doc)\n",
        "  if(sent1_root.pos_ != \"VERB\" and sent1_root.pos_ != \"AUX\"):\n",
        "    #print(\"Relcl: No simplification\")\n",
        "    return False, cmp_snt\n",
        "\n",
        "  order = rel_order(subj)\n",
        "    \n",
        "  sentence1 = remove_punct(sentence1)\n",
        "  sentence2 = remove_punct(sentence2)\n",
        " \n",
        "  if(not order):\n",
        "    #print(sentence1)\n",
        "    #print(sentence2)\n",
        "    return True, sentence1 + \" \" + sentence2\n",
        "  else:\n",
        "    #print(sentence2)\n",
        "    #print(sentence1)\n",
        "    return True, sentence2 + \" \" + sentence1\n",
        "  \n",
        "\n",
        "relative_clause_simplify(\"Prof. Mohan,who teaches art at Delhi University, is a very nice man.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(True,\n",
              " 'Prof. Mohan teaches art at Delhi University. Prof. Mohan is a very nice man.')"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRcvXZlrWa65",
        "outputId": "79ec4a38-fca0-4532-c2a6-a033ec2b9261"
      },
      "source": [
        "relative_clause_simplify(\"Prof. Mohan teaches art in Noida, where he goes to play golf.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(True, 'Prof. Mohan teaches art in Noida. He goes to play golf in Noida.')"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMf0SHoLcLZO",
        "outputId": "b61f9262-6f36-4b67-9ae1-8ea1f4002ef7"
      },
      "source": [
        "relative_clause_simplify('The bar in Barcelona where I met my wife is still there.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(True, 'The bar in Barcelona is still there. I met my wife in Barcelona.')"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtDojAJMcmr3",
        "outputId": "3b0c1763-ff1e-4b71-b17c-452c41eefc8d"
      },
      "source": [
        "relative_clause_simplify(\"My sister, who I live with in Delhi, knows a lot about cars.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(True, 'I live with my sister in Delhi. My sister knows a lot about cars.')"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWt9VVZqmSoi",
        "outputId": "11f648fd-b724-4e2d-991b-7b92b8ff299f"
      },
      "source": [
        "relative_clause_simplify(\"Last week I bought a new computer, which I don't like now.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(True, \"Last week I bought a new computer. I don't like a new computer now.\")"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGsg0jCQmfvD",
        "outputId": "8d925a8e-57c3-4a27-f0f2-a0b103abb1ac"
      },
      "source": [
        "relative_clause_simplify(\"I really love the new Chinese restaurant, which we went to last night.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(True,\n",
              " 'I really love the new Chinese restaurant. We went to the new Chinese restaurant last night.')"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Of2OqYTRmzOn",
        "outputId": "85e2422f-e468-4756-b3ed-783e9cbb7726"
      },
      "source": [
        "relative_clause_simplify(\"The dog whose owner lives next door is over there.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(True, \"The dog's owner lives next door. The dog is over there.\")"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDzkARKwM43k",
        "outputId": "9fa9ecdb-5ded-4e2f-f96f-9545afda0e40"
      },
      "source": [
        "relative_clause_simplify(\"Writer Salman Rushdie, who has been sentenced to die by Iranian zealots, has  donated $8,600 to victims of last week's devastating earthquake in Iran.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(True,\n",
              " \"Writer Salman Rushdie has been sentenced to die by Iranian Zealots. Writer Salman Rushdie has donated $8 600 to victims of last week's devastating earthquake in Iran.\")"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "G9u-9bB73Doi",
        "outputId": "e61f7b60-efeb-4bfd-9971-2b006741de58"
      },
      "source": [
        "#nlp = StanzaLanguage(snlp)\n",
        "snlp = stanza.Pipeline(lang=\"en\")\n",
        "def conjoint_clause_simplification(cmp_snt,snlp):\n",
        "  cmp_snt = cmp_snt.rstrip(\" ,.\")\n",
        "  #snlp = stanza.Pipeline(lang=\"en\")\n",
        "  Qnlp = StanzaLanguage(snlp)\n",
        "  #print('the input is ',cmp_snt)\n",
        "  doc = Qnlp(cmp_snt)\n",
        "  root = get_root_stanza(doc)\n",
        "\n",
        "  clause_type = None\n",
        "    \n",
        "    \n",
        "  clause_type = find_in_children(root, \"conj\")\n",
        "  if(clause_type == None):\n",
        "    clause_type = find_in_children(root, \"advcl\")\n",
        "  if(clause_type == None):\n",
        "    clause_type = find_in_children(root, \"parataxis\")\n",
        "  if(clause_type == None):\n",
        "      clause_type = find_in_subtree(root, \"conj\")\n",
        "  if(clause_type == None):\n",
        "    clause_type = find_in_subtree(root, \"advcl\")\n",
        "  if(clause_type == None):\n",
        "    clause_type = find_in_subtree(root, \"parataxis\")\n",
        "  if(clause_type == None):\n",
        "    #print(\"Conjoint: No simplification(no second clause found)\")\n",
        "    return False, cmp_snt\n",
        "\n",
        "  clause_root = None\n",
        "\n",
        "  if(clause_type.dep_ == \"conj\"):\n",
        "    clause_root = find_in_subtree(root, \"cc\")\n",
        "    if(clause_root != None):\n",
        "      if((not pos_in_subtree(root, \"VERB\")) or (not (pos_in_subtree(clause_type, \"VERB\") or pos_in_subtree(clause_type, \"AUX\")))):\n",
        "        #print(\"Conjoint: No simplification 2(no verb in second clause)\")\n",
        "        return False, cmp_snt\n",
        "    else:\n",
        "      clause_root = find_in_children(clause_type, \"advmod\")\n",
        "  elif(clause_type.dep_ == \"advcl\"):\n",
        "    #print(\"advcl\")\n",
        "    clause_root = find_in_children(clause_type, \"mark\")\n",
        "    if(clause_root == None):\n",
        "      clause_root = find_in_subtree(root, \"mark\")\n",
        "    if(clause_root == None):\n",
        "      clause_root = find_in_children(clause_type, \"advmod\")\n",
        "    if(clause_root != None):\n",
        "        if(clause_root.text == \"to\"):\n",
        "            #print(\"Conjoint: No simplification 3(no conjunction found)\")\n",
        "            return False, cmp_snt\n",
        "  elif(clause_type.dep_ == \"parataxis\"):\n",
        "    #print(\"parataxis\")\n",
        "    clause_root = find_in_children(clause_type, \"advmod\")\n",
        "  else:\n",
        "    #print(\"Conjoint: No simplification 3(no conjunction found)\")\n",
        "    return False, cmp_snt\n",
        "  \n",
        "\n",
        "  if(clause_root == None):\n",
        "    #print(\"Conjoint: No simplification 4\")\n",
        "    return False, cmp_snt\n",
        "  \n",
        "  clause_subj = None\n",
        "\n",
        "  clause_subj = find_in_children(clause_type, \"nsubj\")\n",
        "  if(clause_subj == None):\n",
        "    clause_subj = find_in_children(clause_type, \"nsubj:pass\")\n",
        "  clause_subj_flag = False\n",
        "  if(clause_subj == None):\n",
        "    clause_subj_flag = True\n",
        "    clause_subj = find_in_children(root, \"nsubj\")\n",
        "    if(clause_subj == None):\n",
        "        clause_subj = find_in_children(root, \"nsubj:pass\")\n",
        "    if(clause_subj == None):\n",
        "        #print(\"Conjoint: No simplification(no clause subject found)\")\n",
        "        return False, cmp_snt\n",
        "    aux_str = \"\"\n",
        "    for child in root.children:\n",
        "        if(child.dep_ == \"aux\"):\n",
        "            aux_str += child.text + \" \"\n",
        "  modal = None\n",
        "  if(clause_root.text.lower() in ['when', 'after', 'since', 'before', 'once']):\n",
        "    modal = find_in_subtree(root, \"aux\")\n",
        "\n",
        "  marker1 = \"\"\n",
        "  marker2 = \"\"\n",
        "  if(clause_root.text.lower() == \"if\"):\n",
        "    marker1 = \"Then\"\n",
        "    for child in root.subtree:\n",
        "      if(child.text.lower() == \"then\"):\n",
        "        marker1 = \"\"\n",
        "\n",
        "  sentence1 = inorder_traversal_2(root, [clause_type, clause_root])\n",
        "  \n",
        "  sentence2 = \"\"\n",
        "  marker2 = add_marker(clause_type, clause_root, modal) + \" \"\n",
        "  if(clause_subj_flag):\n",
        "    sentence2 = clause_subj.text + \" \" + aux_str + inorder_traversal(clause_type, clause_root)\n",
        "  else:\n",
        "    sentence2 = inorder_traversal(clause_type, clause_root)\n",
        "\n",
        "  reverse = None\n",
        "\n",
        "  if((root.i > clause_type.i) or (clause_root.text.lower() in [\"because\", \"as\"] and clause_root.i > 0)):\n",
        "    if(clause_root.text.lower() in ['when', 'after', 'since', 'before', 'once'] and clause_root.i == 0):\n",
        "      reverse = False\n",
        "    else:\n",
        "      reverse = True\n",
        "  else:\n",
        "    reverse = False\n",
        "    \n",
        "    \n",
        "  if(clause_root.text.lower() in [\"because\", \"as\"] and clause_root.i > 0):\n",
        "    sentence1 = marker2 + sentence1\n",
        "    sentence2 = marker1 + sentence2\n",
        "  else:\n",
        "    sentence1 = marker1 + sentence1\n",
        "    sentence2 = marker2 + sentence2\n",
        "    \n",
        "  s1 = remove_punct(sentence1)\n",
        "  s2 = remove_punct(sentence2)\n",
        "  exception_list = [\"This happened\", \"This happens\", \"This was\", \"This is\"]\n",
        "  for c in ['when', 'after', 'since', 'before', 'once']:\n",
        "        exception_list.append(\"This is \" + c)\n",
        "        exception_list.append(\"This was \" + c)\n",
        "        exception_list.append(\"This happens \" + c)\n",
        "        exception_list.append(\"This happened \" + c)\n",
        "        if(modal != None):\n",
        "             exception_list.append('This ' + modal.text + ' happen ' + c)\n",
        "  if(s1 in exception_list or s2 in exception_list):\n",
        "        return False, cmp_snt\n",
        "    \n",
        "  if(reverse):\n",
        "    #print(sentence2)\n",
        "    #print(sentence1)\n",
        "    return True, sentence2 + \". \" + sentence1 + \".\"\n",
        "  else:\n",
        "    #print(sentence1)\n",
        "    #print(sentence2)\n",
        "    return True, sentence1 + \". \" + sentence2 + \".\"\n",
        "\n",
        "def add_marker(root, conj,  modal=None):\n",
        "  conj_text = conj.text.lower()\n",
        "  if(conj_text in [\"and\", \"moreover\"]):\n",
        "    return \"And\"\n",
        "  elif(conj_text == \"if\"):\n",
        "    return \"Suppose\"\n",
        "  elif(conj_text in ['though', 'although', 'but', 'whereas', 'however']):\n",
        "    return \"But\"\n",
        "  elif(conj_text in ['when', 'after', 'since', 'before', 'once']):\n",
        "    if(conj.i > 0):\n",
        "      if root.tag_ == 'VBP' or root.tag_ == 'VBZ' or root.tag_ == 'VB':\n",
        "        return 'This is ' + conj_text + \" \"\n",
        "      else:\n",
        "        return 'This was ' + conj_text + \" \"\n",
        "    else:\n",
        "      if root.tag_ == 'VBP' or root.tag_ == 'VBZ':\n",
        "        return 'This happens ' + conj_text + \" \"\n",
        "      elif root.tag_ == 'VB' and modal != None: \n",
        "        return 'This ' + modal.text + ' happen ' + conj_text + \" \"\n",
        "      else:\n",
        "        return 'This happened ' + conj_text + \" \"\n",
        "  elif conj_text in ['because', 'so', 'while', \"therefore\"]:\n",
        "    return 'So '\n",
        "  elif conj_text in [\"nevertheless\", \"nonetheless\", \"yet\"]:\n",
        "    return 'But'\n",
        "  elif conj_text == \"otherwise\":\n",
        "    return 'or'\n",
        "  elif conj_text == \"unless\":\n",
        "    return 'unless'\n",
        "  else:\n",
        "     return \"\"\n",
        "a,b = conjoint_clause_simplification(\"Ram was determined to get high marks nevertheless he did not pass.\",snlp)\n",
        "remove_punct(b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-08-24 17:38:32 INFO: Loading these models for language: en (English):\n",
            "=========================\n",
            "| Processor | Package   |\n",
            "-------------------------\n",
            "| tokenize  | ewt       |\n",
            "| pos       | ewt       |\n",
            "| lemma     | ewt       |\n",
            "| depparse  | ewt       |\n",
            "| sentiment | sstplus   |\n",
            "| ner       | ontonotes |\n",
            "=========================\n",
            "\n",
            "2021-08-24 17:38:32 INFO: Use device: cpu\n",
            "2021-08-24 17:38:32 INFO: Loading: tokenize\n",
            "2021-08-24 17:38:32 INFO: Loading: pos\n",
            "2021-08-24 17:38:33 INFO: Loading: lemma\n",
            "2021-08-24 17:38:33 INFO: Loading: depparse\n",
            "2021-08-24 17:38:34 INFO: Loading: sentiment\n",
            "2021-08-24 17:38:36 INFO: Loading: ner\n",
            "2021-08-24 17:38:36 INFO: Done loading processors!\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Ram was determined to get high marks . But he did not pass.'"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "BzmGRpylHArg",
        "outputId": "1b801419-cdbf-4901-ff11-77a757443f83"
      },
      "source": [
        "a,b = conjoint_clause_simplification(\" bzö  is in favor  of a referendum  about the lisbon treaty  but against an eu-withdrawal.\",snlp)\n",
        "remove_punct(b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Bzö is in favor of a referendum about the Lisbon treaty but against an Eu-Withdrawal'"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvyZP6wk3Doj"
      },
      "source": [
        "def change_verb_form(verb, v_aux, auxpass, subj_tag, subj_word):\n",
        "    word_list = v_aux.split()\n",
        "    new_verb = \"\"\n",
        "    modal_list = [\"can\", \"could\", \"must\", \"should\", \"will\", \"would\", \"may\", \"might\", \"shall\"]\n",
        "    if ('will' in word_list or 'would' in word_list) and auxpass != \"been\":\n",
        "      #print(\"future simple\")\n",
        "      new_verb = v_aux + conjugate(verb, 'pl')\n",
        "    elif auxpass == 'been':\n",
        "      if 'will' in word_list or 'would' in word_list:\n",
        "        #print(\"future perfect\")\n",
        "        new_verb = v_aux + verb\n",
        "      elif 'has' in word_list or 'have' in word_list:\n",
        "        #print(\"present perfect\")\n",
        "        if bool(set(word_list) & set(modal_list)):\n",
        "            new_verb = v_aux + verb\n",
        "        elif subj_tag in (\"NNS\", \"NNPS\") :\n",
        "            new_verb = \"have \" + verb\n",
        "        elif subj_tag in (\"NN\", \"NNP\"):\n",
        "            new_verb = \"has \" + verb\n",
        "        elif subj_tag in (\"PRP\") and subj_word.lower() in (\"them\", \"me\", \"you\"):\n",
        "            new_verb = \"have \" + verb\n",
        "        elif subj_tag in (\"PRP\") and subj_word.lower() in (\"it\", \"her\", \"him\"):\n",
        "            new_verb = \"has \" + verb\n",
        "        else:\n",
        "            new_verb = v_aux + verb\n",
        "      elif 'had' in word_list:\n",
        "        #print(\"past perfect\")\n",
        "        new_verb = v_aux + verb\n",
        "    elif auxpass == \"being\":\n",
        "      if('was' in word_list or 'were' in word_list):\n",
        "        #print(\"past continous\")\n",
        "        if subj_tag in (\"NNS\", \"NNPS\"):\n",
        "            new_verb = \"were \" + conjugate(verb, tense='present', aspect='progressive') \n",
        "        elif subj_tag in (\"NN\", \"NNP\"):\n",
        "            new_verb = \"was \" + conjugate(verb, tense='present', aspect='progressive') \n",
        "        elif subj_tag in (\"PRP\") and subj_word.lower() in (\"them\", \"you\"):\n",
        "            new_verb = \"were \" + conjugate(verb, tense='present', aspect='progressive')\n",
        "        elif subj_tag in (\"PRP\") and subj_word.lower() in (\"me\", \"it\", \"her\", \"him\"):\n",
        "            new_verb = \"was \" + conjugate(verb, tense='present', aspect='progressive')\n",
        "        else:\n",
        "            new_verb = \"was \" + conjugate(verb, tense='present', aspect='progressive')\n",
        "      else:\n",
        "        #print(\"present continous\")\n",
        "        if subj_tag in (\"NNS\", \"NNPS\"):\n",
        "            new_verb = \"are \" + conjugate(verb, tense='present', aspect='progressive') \n",
        "        elif subj_tag in (\"NN\", \"NNP\"):\n",
        "            new_verb = \"is \" + conjugate(verb, tense='present', aspect='progressive') \n",
        "        elif subj_tag in (\"PRP\") and subj_word.lower() in (\"them\", \"you\"):\n",
        "            new_verb = \"are \" + conjugate(verb, tense='present', aspect='progressive')\n",
        "        elif subj_tag in (\"PRP\") and subj_word.lower() in (\"it\", \"her\", \"him\"):\n",
        "            new_verb = \"is \" + conjugate(verb, tense='present', aspect='progressive')\n",
        "        elif subj_tag in (\"PRP\") and subj_word.lower() in (\"me\"):\n",
        "            new_verb = \"am \" + conjugate(verb, tense='present', aspect='progressive')\n",
        "        else:\n",
        "            new_verb = \"is \" + conjugate(verb, tense='present', aspect='progressive')\n",
        "    elif auxpass in ['was', 'were']:\n",
        "      #print(\"simple past\")\n",
        "      if subj_tag in (\"NNS\", \"NNPS\"):\n",
        "        new_verb = conjugate(verb, 'ppl') + \" \"\n",
        "      elif subj_tag in (\"NN\", \"NNP\"):\n",
        "        new_verb = conjugate(verb, '3sgp') + \" \"\n",
        "      elif subj_tag in (\"PRP\") and subj_word.lower() in (\"them\", \"me\", \"you\"):\n",
        "        new_verb = conjugate(verb, 'ppl') + \" \"\n",
        "      elif subj_tag in (\"PRP\") and subj_word.lower() in (\"it\", \"her\", \"him\"):\n",
        "        new_verb = conjugate(verb, '3sgp') + \" \"\n",
        "      else:\n",
        "        new_verb = conjugate(verb, '3sgp') + \" \"\n",
        "    else:\n",
        "      #print(\"simple present\")\n",
        "      if subj_tag in (\"NNS\", \"NNPS\"):\n",
        "        new_verb = conjugate(verb, 'pl') + \" \"\n",
        "      elif subj_tag in (\"NN\", \"NNP\"):\n",
        "        new_verb = conjugate(verb, '3sg') + \" \"\n",
        "      elif subj_tag in (\"PRP\") and subj_word.lower() in (\"them\", \"me\", \"you\"):\n",
        "        new_verb = conjugate(verb, 'pl') + \" \"\n",
        "      elif subj_tag in (\"PRP\") and subj_word.lower() in (\"it\", \"her\", \"him\"):\n",
        "        new_verb = conjugate(verb, '3sg') + \" \"\n",
        "      else:\n",
        "        new_verb = conjugate(verb, '3sg') + \" \"\n",
        "\n",
        "    return new_verb\n",
        "\n",
        "def change_pronoun_object(word):\n",
        "  pron_list = {'me':'I', 'you':'you', 'him':'he', 'her':'she', 'it':'it', 'them':'they', 'us':'we'}\n",
        "  word_list = word.split()\n",
        "  for i in range(len(word_list)):\n",
        "    if(word_list[i] in pron_list.keys()):\n",
        "        word_list[i] = pron_list[word_list[i]]\n",
        "  return \" \".join(str(e) for e in word_list)\n",
        "\n",
        "def change_pronoun_subject(word):\n",
        "  pron_list = {'i':'me', 'you':'you', 'he': 'him', 'she':'her', 'it':'it', 'they':'them', 'we':'us'}\n",
        "  word_list = word.split()\n",
        "  word_list = word.split()\n",
        "  for i in range(len(word_list)):\n",
        "    if(word_list[i].lower() in pron_list.keys()):\n",
        "        word_list[i] = pron_list[word_list[i].lower()]\n",
        "  return \" \".join(str(e) for e in word_list)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "konzRZ_Y3Dok"
      },
      "source": [
        "def passive_simplify(cmp_snt):\n",
        "    nlp=spacy.load('en_core_web_sm')\n",
        "    doc = nlp(cmp_snt)\n",
        "    simplify_flag = False\n",
        "    root = get_root(doc)\n",
        "    auxpass = find_in_children(root, \"auxpass\")\n",
        "    if(auxpass == None):\n",
        "        #print(\"No passive clause found\")\n",
        "        return simplify_flag, cmp_snt\n",
        "    agent = find_in_children(root, \"agent\")\n",
        "    if(agent == None):\n",
        "        #print(\"No agent found\")\n",
        "        return simplify_flag, cmp_snt\n",
        "    subj = find_in_children(root, \"nsubjpass\")\n",
        "    if(subj == None):\n",
        "        #print(\"No subject found\")\n",
        "        return simplify_flag, cmp_snt\n",
        "    \n",
        "    simplify_flag = True\n",
        "    \n",
        "    aux = find_in_children(root, \"aux\")\n",
        "    \n",
        "    aux_tense = auxpass.tag_\n",
        "    if aux_tense == 'VB' and aux != None:\n",
        "        aux_tense = aux.tag_\n",
        "    elif aux_tense == 'VBN' and aux != None:\n",
        "        if aux.text.lower() not in (\"has\", \"have\", \"had\"):\n",
        "            aux_tense = 'MD'\n",
        "\n",
        "    new_obj = inorder_traversal(subj)\n",
        "    obj = find_in_children(agent, \"pobj\")\n",
        "    new_subj = inorder_traversal(obj)\n",
        "    removed_aux = []\n",
        "    for child in root.children:\n",
        "        if(child.dep_ == \"aux\"):\n",
        "            removed_aux.append(child)\n",
        "    \n",
        "    left_of_subj = \"\"\n",
        "    right_of_subj = \"\"\n",
        "    left_of_obj = \"\"\n",
        "    right_of_obj = \"\"\n",
        "    \n",
        "    flag = 0\n",
        "    for child in root.lefts:\n",
        "        if(child.dep_ == \"nsubjpass\"):\n",
        "            flag = 1\n",
        "            continue\n",
        "        if(flag == 0 and child not in [root, subj, auxpass, agent] + removed_aux):\n",
        "            left_of_subj += inorder_traversal(child) + \" \"\n",
        "        elif(flag == 1 and child not in [root, subj, auxpass, agent] + removed_aux):\n",
        "            right_of_subj += inorder_traversal(child) + \" \"\n",
        "            \n",
        "    flag = 0\n",
        "    for child in root.rights:\n",
        "        if(child.dep_ == \"agent\"):\n",
        "            continue\n",
        "        if(((child.dep_ == \"prt\" or child.dep_ == \"prep\") and (len(list(child.children)) == 0)) and child not in [root, subj, auxpass, agent] + removed_aux):\n",
        "            left_of_obj += inorder_traversal(child) + \" \"\n",
        "        elif(child not in [root, subj, auxpass, agent] + removed_aux): \n",
        "            right_of_obj += inorder_traversal(child) + \" \"\n",
        "    \n",
        "    v_aux = \"\"\n",
        "    if(aux != None):\n",
        "        v_aux = aux.text\n",
        "    aux_str = \"\"\n",
        "    for child in root.children:\n",
        "        if(child.dep_ == \"aux\"):\n",
        "            aux_str += child.text + \" \"\n",
        "    if obj==None:\n",
        "      return False, cmp_snt\n",
        "    new_verb = change_verb_form(root.text, aux_str, auxpass.text, obj.tag_, obj.text)\n",
        "    new_subj = change_pronoun_object(new_subj)\n",
        "    new_obj = change_pronoun_subject(new_obj)\n",
        "    final_sent = left_of_subj + \" \" + new_subj + \" \" + right_of_subj + \" \" + new_verb + \" \" + left_of_obj + \" \" + new_obj + \" \" + right_of_obj\n",
        "    final_sent = ' '.join(final_sent.split())   \n",
        "    final_sent = truecase.get_true_case(final_sent)\n",
        "    final_sent = remove_punct(final_sent)\n",
        "    #print(final_sent)\n",
        "    return simplify_flag, final_sent\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CqjAFKd3Dol"
      },
      "source": [
        "def simplify(snt):\n",
        "    Qnlp = StanzaLanguage(snlp)\n",
        "    doc=Qnlp(snt)\n",
        "    flag = False\n",
        "    final_snt = \"\"\n",
        "    for s in doc.sents:\n",
        "        flag, simp_snt = appositive_simplification_2(s.text)\n",
        "        if(flag == True):\n",
        "            #print(simp_snt)\n",
        "            final_snt += (simplify(simp_snt) + \" \")\n",
        "            continue\n",
        "        else:\n",
        "            flag, simp_snt = conjoint_clause_simplification(s.text,snlp)\n",
        "            if(flag == True):\n",
        "                #print(simp_snt)\n",
        "                final_snt += (simplify(simp_snt) + \" \")\n",
        "                continue\n",
        "            else:\n",
        "                flag, simp_snt = relative_clause_simplify(s.text)\n",
        "                if(flag == True):\n",
        "                    final_snt += (simplify(simp_snt) + \" \")\n",
        "                    continue\n",
        "                else:\n",
        "                    flag, simp_snt = passive_simplify(s.text)\n",
        "                    if(flag == True):\n",
        "                        final_snt += (simplify(simp_snt) + \" \")\n",
        "                        continue\n",
        "                    else:\n",
        "                        final_snt += (simp_snt + \" \")\n",
        "    return final_snt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keB4sSjGYwrj"
      },
      "source": [
        "def simplify2(snt):\n",
        "    Qnlp = StanzaLanguage(snlp)\n",
        "    doc=Qnlp(snt)\n",
        "    flag = False\n",
        "    final_snt = \"\"\n",
        "    for s in doc.sents:\n",
        "        flag, simp_snt = appositive_simplification_2(s.text)\n",
        "        if(flag == True):\n",
        "            #print(simp_snt)\n",
        "            final_snt += (simplify2(simp_snt) + \" \")\n",
        "            continue\n",
        "        else:\n",
        "            flag, simp_snt = relative_clause_simplify(s.text)\n",
        "            if(flag == True):\n",
        "                final_snt += (simplify2(simp_snt) + \" \")\n",
        "                continue\n",
        "            else:\n",
        "                flag, simp_snt = passive_simplify(s.text)\n",
        "                if(flag == True):\n",
        "                    final_snt += (simplify2(simp_snt) + \" \")\n",
        "                    continue\n",
        "                else:\n",
        "                    final_snt += (simp_snt + \" \")\n",
        "    \n",
        "    return final_snt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlAJvzWo3Dom"
      },
      "source": [
        "sentence = \"John , who was infected with Covid-19, had quit, before his band released a studio album.\"\n",
        "sentence_simplified = simplify(sentence)\n",
        "sentence_simplified = remove_punct(sentence_simplified)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "Zz9251QYZNAe",
        "outputId": "e95b7469-e75d-4438-da2b-eb2cfab1e2fe"
      },
      "source": [
        "simplify2(sentence)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'John was infected with Covid-19. John had quit before his band released a studio album.  '"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_aQGyFBZ3Don",
        "outputId": "9fd760ce-1701-43f6-d236-5107e2262c6f"
      },
      "source": [
        "print(sentence_simplified)\n",
        "orig_score = textstat.flesch_reading_ease(sentence)\n",
        "final_score = textstat.flesch_reading_ease(sentence_simplified)\n",
        "print(orig_score)\n",
        "print(final_score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "John was infected with Covid - 19 . John had quit . This was before his band released a studio album.\n",
            "64.71\n",
            "73.85\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEZujX943Doo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3Njbh963Dop"
      },
      "source": [
        "sentence = \"Writer Salman Rushdie, who has been sentenced to die by Iranian zealots, has  donated $8,600 to victims of last week's devastating earthquake in Iran.\"\n",
        "sentence_simplified = simplify(sentence)\n",
        "#sentence_simplified = remove_punct(sentence_simplified)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XO6Rd4Oj3Dop",
        "outputId": "708732d0-f09c-478a-e373-f2a48cf0e788"
      },
      "source": [
        "print(sentence_simplified)\n",
        "orig_score = textstat.flesch_reading_ease(sentence)\n",
        "final_score = textstat.flesch_reading_ease(sentence_simplified)\n",
        "print(orig_score)\n",
        "print(final_score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writer Salman Rushdie has been sentenced to die by Iranian Zealots. Rushdie has donated $8 600 to victims of last week's devastating earthquake in Iran.  \n",
            "55.58\n",
            "67.25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0X5FQI33Dou"
      },
      "source": [
        "\n",
        "flag, s = appositive_simplification_2(\"Bob, 31 years old, now qualifies the criteria for nonexecutive director\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQUuRz6F3Dov"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FJejAwv3Dov"
      },
      "source": [
        "flag, s = relative_clause_simplify(\"Prof Mohan, who teaches art at Delhi University, is a very nice man.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "ogzNdAun3Dow",
        "outputId": "2997fe48-8005-4787-b264-9c7b8eb3912c"
      },
      "source": [
        "flag, s = conjoint_clause_simplification(\"She likes to go the tennis club because she likes to play tennis\",snlp)\n",
        "remove_punct(s)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'She likes to play tennis . So she likes to go the tennis club.'"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "vX5TXy2y3Dox",
        "outputId": "ea1f5176-3988-45cd-b840-18b43e41efbc"
      },
      "source": [
        "flag, s = conjoint_clause_simplification(\"Ram was determined to get high marks nevertheless he did not pass\",snlp)\n",
        "remove_punct(s)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Ram was determined to get high marks . But he did not pass.'"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPTLIem43Doy"
      },
      "source": [
        "flag, s = passive_simplify(\"His training regimen had been kept up nicely for a month by him\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "O_qOA8R2QNws",
        "outputId": "b46e7660-56f9-47d4-e27f-7cfef1c0854b"
      },
      "source": [
        "remove_punct(s)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'He had kept up his training regimen nicely for a month'"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDn9Z0xjR3r7"
      },
      "source": [
        "#drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EW3Q3sdVSqdC"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTFobJldRyl2"
      },
      "source": [
        "datadf=pd.read_csv('/content/drive/MyDrive/dataset02/textdata.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "mPsjDwDZSozd",
        "outputId": "232a2715-bc5b-4445-833c-f85d0ccb16c2"
      },
      "source": [
        "datadf.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>docno</th>\n",
              "      <th>fileno</th>\n",
              "      <th>file</th>\n",
              "      <th>text</th>\n",
              "      <th>sentence</th>\n",
              "      <th>length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>d070</td>\n",
              "      <td>ap900129-0036</td>\n",
              "      <td>ap900129-0036.txt</td>\n",
              "      <td>Ousted East German leader Erich Honecker, ...</td>\n",
              "      <td>['    Ousted East German leader Erich Honecker...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>d070</td>\n",
              "      <td>ap900730-0116</td>\n",
              "      <td>ap900730-0116.txt</td>\n",
              "      <td>East Germany's deposed Communist leader Er...</td>\n",
              "      <td>[\"    East Germany's deposed Communist leader ...</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>d070</td>\n",
              "      <td>ap900129-0071</td>\n",
              "      <td>ap900129-0071.txt</td>\n",
              "      <td>Ousted East German leader Erich Honecker w...</td>\n",
              "      <td>['    Ousted East German leader Erich Honecker...</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>d070</td>\n",
              "      <td>ap900118-0029</td>\n",
              "      <td>ap900118-0029.txt</td>\n",
              "      <td>As protests gathered strength last fall, E...</td>\n",
              "      <td>['    As protests gathered strength last fall,...</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>d070</td>\n",
              "      <td>ap900103-0077</td>\n",
              "      <td>ap900103-0077.txt</td>\n",
              "      <td>Former East German leader Erich Honecker m...</td>\n",
              "      <td>['    Former East German leader Erich Honecker...</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  docno  ... length\n",
              "0  d070  ...     10\n",
              "1  d070  ...     12\n",
              "2  d070  ...     20\n",
              "3  d070  ...     25\n",
              "4  d070  ...     12\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-t_uSz2TMbq"
      },
      "source": [
        "datatext=datadf['text'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Omm8w2u_LPZN"
      },
      "source": [
        "datasent=[sent_tokenize(t) for t in datatext]\n",
        "sentlen=[len(s) for s in datasent]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KC_gR7oLMdvI"
      },
      "source": [
        "datadf['sentence']=datasent\n",
        "datadf['length']=sentlen"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "Gv_O9Osir-mF",
        "outputId": "6c2d37f6-03bf-426d-ea5d-246f5b4de798"
      },
      "source": [
        "datadf.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>567.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>28.447972</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>17.729426</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>16.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>26.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>36.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>188.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           length\n",
              "count  567.000000\n",
              "mean    28.447972\n",
              "std     17.729426\n",
              "min      5.000000\n",
              "25%     16.000000\n",
              "50%     26.000000\n",
              "75%     36.000000\n",
              "max    188.000000"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvjLOeZCOr6g"
      },
      "source": [
        "datadf.sort_values(by=['length'],inplace=True)\n",
        "datasent=datadf['sentence']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sOBIgFJPrP7"
      },
      "source": [
        "datasimp=[]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_h-fl2xSSuDa",
        "outputId": "636b508d-9e7b-4e09-b05b-5a5f1c6d4b03"
      },
      "source": [
        "for sent in datasent:\n",
        "  simpsent=[]\n",
        "  for s in sent:\n",
        "    simpsent.append(remove_punct(simplify(s.lstrip(' ').rstrip(' '))))\n",
        "  datasimp.append(simpsent)\n",
        "  df=datadf.iloc[:len(datasimp)]\n",
        "  df['simp']=[' '.join(s)  for s in datasimp]\n",
        "  df['sent_simp']=datasimp\n",
        "  df.to_csv(\"/content/drive/MyDrive/dataset02/textdata_simp_new.csv\", index=None)\n",
        "  print(len(datasimp))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: Due to multiword token expansion or an alignment issue, the original text has been replaced by space-separated expanded tokens.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Here', 'are', 'some', 'quotes', 'on', 'Iraq', \"'s\", 'invasion', 'of', 'Kuwait', '\"', 'The', 'Iraqi', 'government', 'firmly', 'believes', ': .', 'And', 'quotes', 'states', 'that', 'Iraq', 'is', 'pursuing', 'no', 'goal', 'or', 'objective', 'and', 'wishes', 'only', 'cordial', 'relations', 'with', 'Kuwait', '.']\n",
            "Entities: [('Iraq', 'GPE', 28, 32), ('Kuwait', 'GPE', 49, 55), ('Iraqi', 'NORP', 64, 69), ('Iraq', 'GPE', 132, 136), ('Kuwait', 'GPE', 214, 220)]\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "120\n",
            "121\n",
            "122\n",
            "123\n",
            "124\n",
            "125\n",
            "126\n",
            "127\n",
            "128\n",
            "129\n",
            "130\n",
            "131\n",
            "132\n",
            "133\n",
            "134\n",
            "135\n",
            "136\n",
            "137\n",
            "138\n",
            "139\n",
            "140\n",
            "141\n",
            "142\n",
            "143\n",
            "144\n",
            "145\n",
            "146\n",
            "147\n",
            "148\n",
            "149\n",
            "150\n",
            "151\n",
            "152\n",
            "153\n",
            "154\n",
            "155\n",
            "156\n",
            "157\n",
            "158\n",
            "159\n",
            "160\n",
            "161\n",
            "162\n",
            "163\n",
            "164\n",
            "165\n",
            "166\n",
            "167\n",
            "168\n",
            "169\n",
            "170\n",
            "171\n",
            "172\n",
            "173\n",
            "174\n",
            "175\n",
            "176\n",
            "177\n",
            "178\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['It', 'is', 'ironic', '. .', 'This', 'was', 'when', 'just', 'reunification', 'presented', 'a', 'short', '-', 'term', 'reason', '.']\n",
            "Entities: []\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "179\n",
            "180\n",
            "181\n",
            "182\n",
            "183\n",
            "184\n",
            "185\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['His', 'bottom', 'line', ': .', 'Israel', 'did', 'occupy', 'territory', 'that', 'was', 'under', 'another', 'nation', \"'s\", 'sovereignty', '.']\n",
            "Entities: [('Israel', 'GPE', 25, 31)]\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "186\n",
            "187\n",
            "188\n",
            "189\n",
            "190\n",
            "191\n",
            "192\n",
            "193\n",
            "194\n",
            "195\n",
            "196\n",
            "197\n",
            "198\n",
            "199\n",
            "200\n",
            "201\n",
            "202\n",
            "203\n",
            "204\n",
            "205\n",
            "206\n",
            "207\n",
            "208\n",
            "209\n",
            "210\n",
            "211\n",
            "212\n",
            "213\n",
            "214\n",
            "215\n",
            "216\n",
            "217\n",
            "218\n",
            "219\n",
            "220\n",
            "221\n",
            "222\n",
            "223\n",
            "224\n",
            "225\n",
            "226\n",
            "227\n",
            "228\n",
            "229\n",
            "230\n",
            "231\n",
            "232\n",
            "233\n",
            "234\n",
            "235\n",
            "236\n",
            "237\n",
            "238\n",
            "239\n",
            "240\n",
            "241\n",
            "242\n",
            "243\n",
            "244\n",
            "245\n",
            "246\n",
            "247\n",
            "248\n",
            "249\n",
            "250\n",
            "251\n",
            "252\n",
            "253\n",
            "254\n",
            "255\n",
            "256\n",
            "257\n",
            "258\n",
            "259\n",
            "260\n",
            "261\n",
            "262\n",
            "263\n",
            "264\n",
            "265\n",
            "266\n",
            "267\n",
            "268\n",
            "269\n",
            "270\n",
            "271\n",
            "272\n",
            "273\n",
            "274\n",
            "275\n",
            "276\n",
            "277\n",
            "278\n",
            "279\n",
            "280\n",
            "281\n",
            "282\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "TEnfmnncWYCz",
        "outputId": "4db7a286-c04d-4780-cfa5-5bd1b488d010"
      },
      "source": [
        "simplify(s)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"The ship had been fishing illegally in Argentine waters. The ship was Korean.  The Korean ship was sunk by.  This was after  ship  failing   to   answer  to  the Argentine ship 's warnings.  \""
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CpE03hICUgza",
        "outputId": "7700c2a5-81d2-479b-e4e7-6cc7fe5151f5"
      },
      "source": [
        "sent"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' BFN     [Text] Buenos Aires, 23 May (NA) -- Today, the Foreign  Ministry said that control operations carried out by the  corvette Spiro against a Korean-flagged [as received] ship  fishing illegally in Argentine waters were carried out \"in  accordance with international law and in coordination with the  Foreign Ministry.\"',\n",
              " 'The Foreign Ministry thus approved the intervention by the  Argentine corvette when it discovered the Korean ship Chin Yuan  Hsing violating Argentine jurisdictional waters on 21 May.',\n",
              " 'The Argentine Navy reported today that the corvette Spiro  stayed near the Korean ship \"given the adverse weather  conditions, and fulfilling its responsibilities of sea search  and rescue.\"',\n",
              " \"The Korean ship, which had been fishing illegally in  Argentine waters, was sunk by its own crew after failing to  answer to the Argentine ship's warnings.\",\n",
              " 'The crew was transferred to the Chin Chuan Hsing, which was  sailing nearby and approached to rescue the crew of the sinking  ship.',\n",
              " 'The Navy reported that around 15 nautical miles off the  coast  of Malvinas and \"in accordance with bilateral agreements with  Great Britain, the Spiro transferred assistance responsibility  to British authorities.\"',\n",
              " 'The Foreign Ministry said \"an understanding with the UK for  operations in cases of uninterrupted persecution of illegally  fishing ships was implemented.\"',\n",
              " 'The Foreign Ministry also said the policy \"is in accordance  with the growing international opinion currently giving priority  to the preservation, regulation, and the sustainable use of  marine live resources and the effective punishment of violators  of national laws on the matter.\"']"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fh_IwkEwTFe4",
        "outputId": "36cb26d2-e6ca-4255-ee2e-06ae5e7768c2"
      },
      "source": [
        "datasent[2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['    Ousted East German leader Erich Honecker was arrested and taken to prison today, and a prosecutor said he will tried for high treason in March.',\n",
              " \"Honecker, 77, was detained after his release from East Berlin's Charite hospital, where he had undergone surgery for a malignant kidney tumor, the official ADN news agency said.\",\n",
              " 'Chief Prosecutor Hans-Juergen Joseph told Parliament that Honecker and former Politburo members Erich Mielke, Guenter Mittag and Joachim Herrmann would be tried by the Supreme Court on treason charges in March.',\n",
              " 'All four have been expelled from the party.',\n",
              " \"Mielke was Honecker's security chief, Mittag oversaw the economy and Herrmann headed the party's propaganda department.\",\n",
              " \"Eleven members of Honecker's ousted Politburo already are in prison awaiting trial.\",\n",
              " \"Honecker's lawyer, Wolfgang Vogel, asked the chief prosecutor to free the former leader from Rummelburg prison based on a doctor's statement that he is too ill to stay in jail, ADN said.\",\n",
              " \"Vogel is East Germany's most prominent lawyer.\",\n",
              " 'One of Honecker\\'s doctors, Horst Vogler, said the former leader was \"very depressed\" and his mental state \"impaired\" following two major surgical operations since August.',\n",
              " 'West German television showed an impassive Honecker being led out of the hospital by his wife, Margot, in pre-dawn darkness.',\n",
              " 'She kissed him goodbye before he was taken away in a large limousine.',\n",
              " \"Honecker's daughter, son-in-law and youngest grandchild also came to see him off at the hospital, ADN quoted Vogler as saying.\",\n",
              " 'The charge of high treason carries a maximum life imprisonment.',\n",
              " \"The conviction used to carry the death penalty, but that was abolished in reforms that followed Honecker's ouster Oct. 18.\",\n",
              " 'East Germany has been caught up in a virtual frenzy to root out corruption and abuse of office.',\n",
              " 'Honecker, the aging hard-line Stalinist leader who ruled East Germany for 18 years, had previously been declared too ill to withstand imprisonment.',\n",
              " 'ADN said the director of Charite urology clinic, Dr. Peter Althaus, repeated today that in his opinion Honecker is still not well enough to be jailed.',\n",
              " \"On Sunday, West Germany's mass-circulation Bild newspaper said Honecker would be arrested but that he would be held at a prison hospital because of his condition.\",\n",
              " 'ADN did not say whether Rummelsburg prison is equipped with a medical facility.',\n",
              " \"Earlier this month, East Germany's Luthern Church had offered to put Honecker up in a home for the aged upon his release from the hospital.\"]"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOgTmgfA45uO",
        "outputId": "52c27731-e6b0-4bdb-a484-0ee3f67536c1"
      },
      "source": [
        "len(sent)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHMtN9UtQCSt",
        "outputId": "7565c6f2-0c01-4179-c871-7f45683cecd9"
      },
      "source": [
        "len(simpsent)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9_SO9MDPjJv",
        "outputId": "63488d2c-8c79-4908-8a0a-1da312735250"
      },
      "source": [
        "len(datasimp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "79"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Lvts3Db396M",
        "outputId": "653f38f0-f219-4d4b-cd5e-fb83b23a47ed"
      },
      "source": [
        "df=datadf.iloc[:len(datasimp)]\n",
        "df['simp']=[' '.join(s)  for s in datasimp]\n",
        "df['sent_simp']=datasimp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "qJg5SS1l4OeV",
        "outputId": "e703b874-abb7-4a02-994b-59e827d705f2"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>docno</th>\n",
              "      <th>fileno</th>\n",
              "      <th>file</th>\n",
              "      <th>text</th>\n",
              "      <th>sentence</th>\n",
              "      <th>length</th>\n",
              "      <th>simp</th>\n",
              "      <th>sent_simp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>d070</td>\n",
              "      <td>ap900129-0036</td>\n",
              "      <td>ap900129-0036.txt</td>\n",
              "      <td>Ousted East German leader Erich Honecker, ...</td>\n",
              "      <td>[    Ousted East German leader Erich Honecker,...</td>\n",
              "      <td>10</td>\n",
              "      <td>Ousted East German leader Erich Honecker who i...</td>\n",
              "      <td>[Ousted East German leader Erich Honecker who ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>d070</td>\n",
              "      <td>ap900730-0116</td>\n",
              "      <td>ap900730-0116.txt</td>\n",
              "      <td>East Germany's deposed Communist leader Er...</td>\n",
              "      <td>[    East Germany's deposed Communist leader E...</td>\n",
              "      <td>12</td>\n",
              "      <td>East Germany's deposed Communist leader Erich ...</td>\n",
              "      <td>[East Germany's deposed Communist leader Erich...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>d070</td>\n",
              "      <td>ap900129-0071</td>\n",
              "      <td>ap900129-0071.txt</td>\n",
              "      <td>Ousted East German leader Erich Honecker w...</td>\n",
              "      <td>[    Ousted East German leader Erich Honecker ...</td>\n",
              "      <td>20</td>\n",
              "      <td>Ousted East German leader Erich Honecker was a...</td>\n",
              "      <td>[Ousted East German leader Erich Honecker was ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>d070</td>\n",
              "      <td>ap900118-0029</td>\n",
              "      <td>ap900118-0029.txt</td>\n",
              "      <td>As protests gathered strength last fall, E...</td>\n",
              "      <td>[    As protests gathered strength last fall, ...</td>\n",
              "      <td>25</td>\n",
              "      <td>Protests gathered strength last Fall.. East Ge...</td>\n",
              "      <td>[Protests gathered strength last Fall.. East G...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>d070</td>\n",
              "      <td>ap900103-0077</td>\n",
              "      <td>ap900103-0077.txt</td>\n",
              "      <td>Former East German leader Erich Honecker m...</td>\n",
              "      <td>[    Former East German leader Erich Honecker ...</td>\n",
              "      <td>12</td>\n",
              "      <td>Former East German leader Erich Honecker may b...</td>\n",
              "      <td>[Former East German leader Erich Honecker may ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  docno  ...                                          sent_simp\n",
              "0  d070  ...  [Ousted East German leader Erich Honecker who ...\n",
              "1  d070  ...  [East Germany's deposed Communist leader Erich...\n",
              "2  d070  ...  [Ousted East German leader Erich Honecker was ...\n",
              "3  d070  ...  [Protests gathered strength last Fall.. East G...\n",
              "4  d070  ...  [Former East German leader Erich Honecker may ...\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nc3lcwIl4DrV",
        "outputId": "0539758d-18ef-425f-c1ee-e36343134db5"
      },
      "source": [
        "len(df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "79"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83CAZJv24k2i"
      },
      "source": [
        "df.to_csv(\"/content/drive/MyDrive/dataset02/textdata_simp.csv\", index=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "id": "2PmtqkOX002R",
        "outputId": "c5ef6544-e316-435e-fb43-add3f2743e02"
      },
      "source": [
        "datadf['simp']=datasimp\n",
        "datadf.to_csv(\"/content/drive/MyDrive/dataset02/textdata_simp.csv\", index=None)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-133-0a192dd99507>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdatadf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'simp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatasimp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdatadf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/dataset02/textdata_simp.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3042\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3043\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3044\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3046\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3118\u001b[0m         \"\"\"\n\u001b[1;32m   3119\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3120\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3121\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, key, value, broadcast)\u001b[0m\n\u001b[1;32m   3766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3767\u001b[0m             \u001b[0;31m# turn me into an ndarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3768\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msanitize_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3769\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3770\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36msanitize_index\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    746\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m         raise ValueError(\n\u001b[0;32m--> 748\u001b[0;31m             \u001b[0;34m\"Length of values \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    749\u001b[0m             \u001b[0;34mf\"({len(data)}) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0;34m\"does not match length of index \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Length of values (31) does not match length of index (567)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVvn4t4Gx5p4",
        "outputId": "48e13591-6087-464f-be26-2f97ee07aa4a"
      },
      "source": [
        "sent"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['    Ousted East German leader Erich Honecker was arrested and taken to prison today, and a prosecutor said he will tried for high treason in March.',\n",
              " \"Honecker, 77, was detained after his release from East Berlin's Charite hospital, where he had undergone surgery for a malignant kidney tumor, the official ADN news agency said.\",\n",
              " 'Chief Prosecutor Hans-Juergen Joseph told Parliament that Honecker and former Politburo members Erich Mielke, Guenter Mittag and Joachim Herrmann would be tried by the Supreme Court on treason charges in March.',\n",
              " 'All four have been expelled from the party.',\n",
              " \"Mielke was Honecker's security chief, Mittag oversaw the economy and Herrmann headed the party's propaganda department.\",\n",
              " \"Eleven members of Honecker's ousted Politburo already are in prison awaiting trial.\",\n",
              " \"Honecker's lawyer, Wolfgang Vogel, asked the chief prosecutor to free the former leader from Rummelburg prison based on a doctor's statement that he is too ill to stay in jail, ADN said.\",\n",
              " \"Vogel is East Germany's most prominent lawyer.\",\n",
              " 'One of Honecker\\'s doctors, Horst Vogler, said the former leader was \"very depressed\" and his mental state \"impaired\" following two major surgical operations since August.',\n",
              " 'West German television showed an impassive Honecker being led out of the hospital by his wife, Margot, in pre-dawn darkness.',\n",
              " 'She kissed him goodbye before he was taken away in a large limousine.',\n",
              " \"Honecker's daughter, son-in-law and youngest grandchild also came to see him off at the hospital, ADN quoted Vogler as saying.\",\n",
              " 'The charge of high treason carries a maximum life imprisonment.',\n",
              " \"The conviction used to carry the death penalty, but that was abolished in reforms that followed Honecker's ouster Oct. 18.\",\n",
              " 'East Germany has been caught up in a virtual frenzy to root out corruption and abuse of office.',\n",
              " 'Honecker, the aging hard-line Stalinist leader who ruled East Germany for 18 years, had previously been declared too ill to withstand imprisonment.',\n",
              " 'ADN said the director of Charite urology clinic, Dr. Peter Althaus, repeated today that in his opinion Honecker is still not well enough to be jailed.',\n",
              " \"On Sunday, West Germany's mass-circulation Bild newspaper said Honecker would be arrested but that he would be held at a prison hospital because of his condition.\",\n",
              " 'ADN did not say whether Rummelsburg prison is equipped with a medical facility.',\n",
              " \"Earlier this month, East Germany's Luthern Church had offered to put Honecker up in a home for the aged upon his release from the hospital.\"]"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62-VX0yfwICE",
        "outputId": "7831a31c-298a-47cc-c496-7c70ddd9f5fd"
      },
      "source": [
        "len(datasimp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJFZLhkJtW-q",
        "outputId": "b38d1334-f0e6-4480-8cfe-5092119454f6"
      },
      "source": [
        "datasimp[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"East Germany's deposed Communist leader Erich Honecker is too sick to be held in jail . But Erich is fit enough to be tried the official news agency reported Monday . The news agency was ADN . The news agency was official.\",\n",
              " 'Adn, quoting a health Ministry statement, said Honecker was still recovering from surgery for kidney cancer in January and was not well enough to be incarcerated.',\n",
              " 'But a exam by a team of doctors found him in condition to be questioned and to stand trial ADN said . A exam was medical.',\n",
              " 'Honecker ruled he was ousted in October as a wave of pro - democracy demonstrations . East Germany for 19 years swept the country leading to the peaceful overthrow of the Communist government and the opening of the Berlin wall . Honecker was 77.',\n",
              " \"Had been seven officials among Honecker's closest aides . The panel concluded that seven officials were all fit to prosecute and to be placed in custody ADN said . seven officials were Communist . seven officials were former . seven officials were Communist . seven officials were other . seven officials were Communist . seven officials were former . seven officials were Communist . The panel was medical.\",\n",
              " 'It said former secret police chief Erich Mielke, former economics czar Guenter Mittag and former labor chief Harry Tisch were under arrest, while the other four remained free.',\n",
              " 'All three had been members of the ruling Politburo under Honecker.',\n",
              " 'Mielke was arrested on Thursday.',\n",
              " 'Honecker and the seven are charged with corruption and abuse of office.',\n",
              " \"They had been arrested soon after Honecker's fall . But they had were later released because of advanced age and poor health.\",\n",
              " 'Honecker has been staying at a Soviet military hospital outside East Berlin.',\n",
              " 'Adn saying he intended to continue his investigation against the former East German Leaders.. but their health often disrupted the proceedings . their health was poor . ADN quoted Federal Prosecutor Guenter Seidel.']"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Kds8WrrTFk6",
        "outputId": "cd5dc394-ee90-4946-c21c-5cf76858c0fe"
      },
      "source": [
        "sent"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['    Ousted East German leader Erich Honecker, who is expected to be indicted for high treason, was arrested Monday morning upon release from a hospital and taken to prison, the official news agency ADN said.',\n",
              " \"The news agency said the 77-year-old Honecker was arrested after being released from East Berlin's Charite hospital, where he had undergone surgery for a malignant kidney tumor.\",\n",
              " \"Honecker was immediately taken to East Berlin's Rummelsburg prison, the brief dispatch said.\",\n",
              " 'Honecker joins other members of his ousted Politburo already in prison awaiting trial.',\n",
              " 'Earlier this month, East German prosecutors said Honecker and former state security chief Erich Mielke would be charged with treason and corruption charges for misuse of their positions and state funds.',\n",
              " 'Honecker, the aging hard-line Stalinist leader who ruled East Germany for 18 years until his ouster on Oct. 18, had previously been declared too ill to withstand imprisonment.',\n",
              " 'ADN said that the director of Charite urology clinic, Dr. Peter Althaus, repeated on Monday that in his opinion Honecker was still not well enough to be jailed.',\n",
              " \"On Sunday, West Germany's mass-circulation Bild newspaper said Honecker would be arrested, but that he would be held at a prison hospital because of his condition.\",\n",
              " 'ADN made not mention if Rummelsburg prison was equipped with a medical facility.',\n",
              " \"Earlier this month, East Germany's Luthern Church had offered to put Honecker up in a home for the aged upon his release from the hospital.\"]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3AqGinYzS0JH",
        "outputId": "7787e778-beed-48a4-d2ed-115830612bb9"
      },
      "source": [
        "simpsent=[remove_punct(simplify(s)) for s in sent]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ousted East German leader Erich Honecker who is expected to be indicted for high treason was arrested Monday morning upon release from a hospital and taken to prison the official news agency said.\n",
            "The official news agency was ADN.\n",
            "Ousted East German leader Erich Honecker who is expected to be indicted for high treason was arrested Monday morning upon release from a hospital and taken to prison the official news agency said. The official news agency was ADN.\n",
            "Appos: No simplification(no subject)\n",
            "the input is  Ousted East German leader Erich Honecker who is expected to be indicted for high treason was arrested Monday morning upon release from a hospital and taken to prison the official news agency said\n",
            "  Ousted East German leader  Erich Honecker  who is expected  to be indicted  for high treason was arrested  Monday morning  upon release  from a hospital   the official news agency said\n",
            "And leader  taken  to prison\n",
            "  Ousted East German leader  Erich Honecker  who is expected  to be indicted  for high treason was arrested  Monday morning  upon release  from a hospital   the official news agency said. And leader  taken  to prison.\n",
            "Appos: No simplification(no subject)\n",
            "the input is    Ousted East German leader  Erich Honecker  who is expected  to be indicted  for high treason was arrested  Monday morning  upon release  from a hospital   the official news agency said\n",
            "Conjoint: No simplification(no second clause found)\n",
            "Relcl: No simplification\n",
            "No passive clause found\n",
            "Appos: No simplification\n",
            "the input is  And leader  taken  to prison\n",
            "Conjoint: No simplification(no second clause found)\n",
            "Relcl: No simplification\n",
            "No passive clause found\n",
            "The news agency was ADN.\n",
            "The news agency was official.\n",
            "The news agency was ADN. The news agency was official.\n",
            "Appos: No simplification\n",
            "the input is  The news agency was ADN\n",
            "Conjoint: No simplification(no second clause found)\n",
            "Relcl: No simplification\n",
            "No passive clause found\n",
            "Appos: No simplification\n",
            "the input is  The news agency was official\n",
            "Conjoint: No simplification(no second clause found)\n",
            "Relcl: No simplification\n",
            "No passive clause found\n",
            "Appos: No simplification(no subject)\n",
            "the input is  The news agency said the 77-year-old Honecker was arrested after being released from East Berlin's Charite hospital, where he had undergone surgery for a malignant kidney tumor\n",
            "advcl\n",
            "  The news agency said   the   77 - year - old Honecker was arrested\n",
            "This was after  agency  being released  from  East Berlin 's Charite hospital ,  where he had undergone surgery  for a malignant kidney tumor\n",
            "  The news agency said   the   77 - year - old Honecker was arrested. This was after  agency  being released  from  East Berlin 's Charite hospital ,  where he had undergone surgery  for a malignant kidney tumor.\n",
            "Appos: No simplification(no subject)\n",
            "the input is    The news agency said   the   77 - year - old Honecker was arrested\n",
            "Conjoint: No simplification(no second clause found)\n",
            "Relcl: No simplification\n",
            "No passive clause found\n",
            "Appos: No simplification(no subject)\n",
            "the input is  This was after  agency  being released  from  East Berlin 's Charite hospital ,  where he had undergone surgery  for a malignant kidney tumor\n",
            "Conjoint: No simplification(no second clause found)\n",
            "Appos: No simplification\n",
            "the input is  This was after agency being released from East Berlin's Charite hospital\n",
            "Conjoint: No simplification(no second clause found)\n",
            "Relcl: No simplification\n",
            "No passive clause found\n",
            "Appos: No simplification(no subject)\n",
            "the input is  He had undergone surgery for a malignant kidney tumor at East Berlin's Charite hospital\n",
            "Conjoint: No simplification(no second clause found)\n",
            "Relcl: No simplification\n",
            "No passive clause found\n",
            "Honecker was immediately taken to East Berlin's Rummelsburg prison the dispatch said.\n",
            "The dispatch was brief.\n",
            "Honecker was immediately taken to East Berlin's Rummelsburg prison the dispatch said. The dispatch was brief.\n",
            "Appos: No simplification\n",
            "the input is  Honecker was immediately taken to East Berlin's Rummelsburg prison the dispatch said\n",
            "parataxis\n",
            "Conjoint: No simplification 4\n",
            "Relcl: No simplification\n",
            "No passive clause found\n",
            "Appos: No simplification\n",
            "the input is  The dispatch was brief\n",
            "Conjoint: No simplification(no second clause found)\n",
            "Relcl: No simplification\n",
            "No passive clause found\n",
            "Appos: No simplification(no subject)\n",
            "the input is  Honecker joins other members of his ousted Politburo already in prison awaiting trial\n",
            "Conjoint: No simplification(no second clause found)\n",
            "Relcl: No simplification\n",
            "No passive clause found\n",
            "Appos: No simplification(no subject)\n",
            "the input is  Earlier this month, East German prosecutors said Honecker and former state security chief Erich Mielke would be charged with treason and corruption charges for misuse of their positions and state funds\n",
            "Conjoint: No simplification 2(no verb in second clause)\n",
            "Relcl: No simplification\n",
            "No passive clause found\n",
            "Honecker had previously been declared too ill to withstand imprisonment.\n",
            "Honecker was the aging hard - line Stalinist leader who ruled East Germany for 18 years until his ouster on Oct. 18.\n",
            "Honecker had previously been declared too ill to withstand imprisonment. Honecker was the aging hard - line Stalinist leader who ruled East Germany for 18 years until his ouster on Oct. 18.\n",
            "Appos: No simplification\n",
            "the input is  Honecker had previously been declared too ill to withstand imprisonment\n",
            "advcl\n",
            "Conjoint: No simplification 3(no conjunction found)\n",
            "Relcl: No simplification\n",
            "No agent found\n",
            "Appos: No simplification(no subject)\n",
            "the input is  Honecker was the aging hard - line Stalinist leader who ruled East Germany for 18 years until his ouster on Oct. 18\n",
            "Conjoint: No simplification(no second clause found)\n",
            "Appos: No simplification(no subject)\n",
            "the input is  Honecker was the aging hard - line Stalinist leader\n",
            "Conjoint: No simplification(no second clause found)\n",
            "Relcl: No simplification\n",
            "No passive clause found\n",
            "The hard - line Stalinist leader ruled East Germany for 18 years until his ouster on Oct. 18.\n",
            "The hard - line Stalinist leader was aging.\n",
            "The hard - line Stalinist leader ruled East Germany for 18 years until his ouster on Oct. 18. The hard - line Stalinist leader was aging.\n",
            "Appos: No simplification(no subject)\n",
            "the input is  The hard - line Stalinist leader ruled East Germany for 18 years until his ouster on Oct. 18\n",
            "Conjoint: No simplification(no second clause found)\n",
            "Relcl: No simplification\n",
            "No passive clause found\n",
            "Appos: No simplification(no subject)\n",
            "the input is  The hard - line Stalinist leader was aging\n",
            "Conjoint: No simplification(no second clause found)\n",
            "Relcl: No simplification\n",
            "No passive clause found\n",
            "Adn said that the director of Charite Urology clinic repeated on Monday that in his opinion Honecker was still not well enough to be jailed.\n",
            "The director was Dr. Peter Althaus.\n",
            "Adn said that the director of Charite Urology clinic repeated on Monday that in his opinion Honecker was still not well enough to be jailed. The director was Dr. Peter Althaus.\n",
            "Appos: No simplification\n",
            "the input is  Adn said that the director of Charite Urology clinic repeated on Monday that in his opinion Honecker was still not well enough to be jailed\n",
            "advcl\n",
            "Conjoint: No simplification 3(no conjunction found)\n",
            "Relcl: No simplification\n",
            "No passive clause found\n",
            "Appos: No simplification\n",
            "the input is  The director was Dr. Peter Althaus\n",
            "Conjoint: No simplification(no second clause found)\n",
            "Relcl: No simplification\n",
            "No passive clause found\n",
            "Appos: No simplification\n",
            "the input is  On Sunday, West Germany's mass-circulation\n",
            "Conjoint: No simplification(no second clause found)\n",
            "Relcl: No simplification\n",
            "No passive clause found\n",
            "Appos: No simplification\n",
            "the input is  Bild newspaper said Honecker would be arrested, but that he would be held at a prison hospital because of his condition\n",
            "  Bild newspaper said  Honecker would be arrested\n",
            "But  , that he would be held  at a prison hospital   because of his condition\n",
            "  Bild newspaper said  Honecker would be arrested. But  , that he would be held  at a prison hospital   because of his condition.\n",
            "Appos: No simplification\n",
            "the input is    Bild newspaper said  Honecker would be arrested\n",
            "Conjoint: No simplification(no second clause found)\n",
            "Relcl: No simplification\n",
            "No passive clause found\n",
            "Appos: No simplification\n",
            "the input is  But  , that he would be held  at a prison hospital   because of his condition\n",
            "Conjoint: No simplification(no second clause found)\n",
            "Relcl: No simplification\n",
            "No agent found\n",
            "Appos: No simplification(no subject)\n",
            "the input is  ADN made not mention if Rummelsburg prison was equipped with a medical facility\n",
            "advcl\n",
            "Then ADN made not mention\n",
            "Suppose   Rummelsburg prison was equipped  with a medical facility\n",
            "Then ADN made not mention. Suppose   Rummelsburg prison was equipped  with a medical facility.\n",
            "Appos: No simplification\n",
            "the input is  Then ADN made not mention\n",
            "Conjoint: No simplification(no second clause found)\n",
            "Relcl: No simplification\n",
            "No passive clause found\n",
            "Appos: No simplification(no subject)\n",
            "the input is  Suppose   Rummelsburg prison was equipped  with a medical facility\n",
            "Conjoint: No simplification(no second clause found)\n",
            "Relcl: No simplification\n",
            "No passive clause found\n",
            "Appos: No simplification\n",
            "the input is  Earlier this month, East Germany's Luthern Church had offered to put Honecker up in a home for the aged upon his release from the hospital\n",
            "Conjoint: No simplification(no second clause found)\n",
            "Relcl: No simplification\n",
            "No passive clause found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMLiU6SbTAJW",
        "outputId": "5eabbc16-41ad-44d6-ea88-bff2ee2bce2b"
      },
      "source": [
        "simpsent"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Ousted East German leader Erich Honecker who is expected to be indicted for high treason was arrested Monday morning upon release from a hospital the official news agency said . and leader taken to prison . The news agency was ADN . The news agency was official.',\n",
              " \"The news agency said the 77 - year - old Honecker was arrested . This was after agency being released from East Berlin's Charite hospital . He had undergone surgery for a malignant kidney tumor at East Berlin's Charite hospital.\",\n",
              " \"Honecker was immediately taken to East Berlin's Rummelsburg prison the dispatch said . The dispatch was brief.\",\n",
              " 'Honecker joins other members of his ousted Politburo already in prison awaiting trial.',\n",
              " 'Earlier this month, East German prosecutors said Honecker and former state security chief Erich Mielke would be charged with treason and corruption charges for misuse of their positions and state funds.',\n",
              " 'Honecker had previously been declared too ill to withstand imprisonment . Honecker was the aging hard - line Stalinist leader . The hard - line Stalinist leader ruled East Germany for 18 years until his ouster on Oct. 18 . The hard - line Stalinist leader was aging.',\n",
              " 'Adn said that the director of Charite Urology clinic repeated on Monday that in his opinion Honecker was still not well enough to be jailed . The director was Dr. Peter Althaus.',\n",
              " \"On Sunday, West Germany's Mass-Circulation Bild newspaper said Honecker would be arrested . But . that he would be held at a prison hospital because of his condition.\",\n",
              " 'Then ADN made not mention . Suppose Rummelsburg prison was equipped with a medical facility.',\n",
              " \"Earlier this month, East Germany's Luthern church had offered to put Honecker up in a home for the aged upon his release from the hospital.\"]"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSUdnLzwTvQi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}